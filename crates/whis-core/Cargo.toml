[package]
name = "whis-core"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true
description = "Core library for whis voice-to-text functionality"

[dependencies]
anyhow.workspace = true
tokio.workspace = true
serde.workspace = true
serde_json.workspace = true
reqwest = { workspace = true, features = ["blocking", "multipart", "json", "stream"] }
futures-util = "0.3"
cpal.workspace = true
hound = { workspace = true, optional = true }
arboard = { workspace = true, optional = true }
dotenvy.workspace = true
dirs = "5"
async-trait = "0.1"

# Embedded MP3 encoder for mobile (no FFmpeg dependency)
mp3lame-encoder = { version = "0.2", optional = true }

# Real-time resampling to 16kHz (always enabled - benefits all providers)
rubato = "0.15"

# Voice Activity Detection using Silero VAD model
voice_activity_detector = { version = "0.2", optional = true }

# Local transcription (optional)
whisper-rs = { version = "0.15.1", optional = true }
minimp3 = { version = "0.5", optional = true }

[features]
default = ["ffmpeg", "clipboard", "local-whisper", "vad"]
# Desktop: use FFmpeg process for audio encoding and arboard for clipboard
ffmpeg = ["hound"]
clipboard = ["arboard"]
# Mobile: use embedded mp3lame encoder (no external process needed)
embedded-encoder = ["mp3lame-encoder"]
# Local whisper.cpp transcription (requires model download)
local-whisper = ["whisper-rs", "minimp3"]
# Voice Activity Detection to skip silence during recording
vad = ["voice_activity_detector"]
